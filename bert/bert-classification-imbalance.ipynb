{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tPRCuE6HSZfx"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import string\n",
        "import transformers\n",
        "from pandas import DataFrame\n",
        "from typing import Tuple\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from tensorflow.python.keras.layers import Input, Dropout, Dense\n",
        "from tensorflow.python.keras.models import Model\n",
        "from tensorflow.python.keras.metrics import BinaryAccuracy, Precision, Recall\n",
        "\n",
        "MARKER_COLUMN_NAME = 'MARKER'\n",
        "CLASSE_COLUMN_NAME = 'DES_CLASSE'\n",
        "EMENTA_COLUMN_NAME = 'TXT_EMENTA'\n",
        "METRICS = [\n",
        "    BinaryAccuracy(name='accuracy'),\n",
        "    Precision(name='precision'),\n",
        "    Recall(name='recall')\n",
        "]\n",
        "\n",
        "\n",
        "def separate_datasets(df: DataFrame, classe: string) -> Tuple[DataFrame, DataFrame]:\n",
        "    print(\"Separando datasets\")\n",
        "    df_classe = df[df[CLASSE_COLUMN_NAME] == \"'\"+classe+\"'\"]\n",
        "    print(\"Dataset da classe-alvo:\", df_classe.shape)\n",
        "    df_outrasClasses = df[df[CLASSE_COLUMN_NAME] != \"'\"+classe+\"'\"]\n",
        "    print(\"Dataset das outras classes:\", df_outrasClasses.shape)\n",
        "    return df_classe, df_outrasClasses\n",
        "\n",
        "\n",
        "def create_downsample_df(df_classe: DataFrame, df_outrasClasses: DataFrame) -> DataFrame:\n",
        "    quantidadeDeRegistros = df_classe.shape[0]\n",
        "    print(\"Criando um dataset das outras classes com \",\n",
        "          quantidadeDeRegistros, \" registros\")\n",
        "    return df_outrasClasses.sample(quantidadeDeRegistros)\n",
        "\n",
        "\n",
        "def create_balanced_df(df_classe: DataFrame, df_outrasClasses: DataFrame, classeColumnName: string) -> DataFrame:\n",
        "    df_outrasClasses_downsampled = create_downsample_df(\n",
        "        df_classe, df_outrasClasses)\n",
        "    print(\"Juntando os datasets...\")\n",
        "    df_balanced = pd.concat([df_outrasClasses_downsampled, df_classe])\n",
        "    print('Verificando a quantidade de classes existentes no DataFrame apÃ³s o balanceamento:')\n",
        "    print(df_balanced[classeColumnName].value_counts())\n",
        "    return df_balanced\n",
        "\n",
        "\n",
        "def mark_classe(df_balanced: DataFrame, classe: string):\n",
        "    print(\"Incluindo marcador na classe \", classe)\n",
        "    df_balanced[MARKER_COLUMN_NAME] = df_balanced[CLASSE_COLUMN_NAME].apply(\n",
        "        lambda x: 1 if x == \"'\"+classe+\"'\" else 0)\n",
        "    print(\"Verificando marcadores:\")\n",
        "    print(df_balanced.sample(5))\n",
        "\n",
        "\n",
        "def create_keras_model() -> Model:\n",
        "    bert_preprocess = AutoTokenizer.from_pretrained(\n",
        "        'neuralmind/bert-large-portuguese-cased')\n",
        "    bert_encoder = AutoModel.from_pretrained(\n",
        "        'neuralmind/bert-large-portuguese-cased')\n",
        "\n",
        "    # Bert layers\n",
        "    text_input = Input(shape=(), dtype=tf.string, name='text')\n",
        "    preprocessed_text = bert_preprocess(text_input)\n",
        "    outputs = bert_encoder(preprocessed_text)\n",
        "\n",
        "    # Neural network layers\n",
        "    l = Dropout(0.1, name=\"dropout\")(outputs['pooled_output'])\n",
        "    l = Dense(1, activation='sigmoid', name=\"output\")(l)\n",
        "\n",
        "    # Use inputs and outputs to construct a final model\n",
        "    model = Model(inputs=[text_input], outputs=[l])\n",
        "    print(model.summary)\n",
        "    return model\n",
        "\n",
        "\n",
        "def evaluate_model(model: Model, X_test: list):\n",
        "    y_predicted = model.predict(X_test)\n",
        "    y_predicted = y_predicted.flatten()\n",
        "    y_predicted = np.where(y_predicted > 0.5, 1, 0)\n",
        "    print(y_predicted)\n",
        "\n",
        "\n",
        "def train_class(df: DataFrame, classe: string,  balanceRatio=0) -> Model:\n",
        "    print('Verificando a quantidade de classes existentes no DataFrame')\n",
        "    print(df[CLASSE_COLUMN_NAME].value_counts())\n",
        "    df_classe, df_outrasClasses = separate_datasets(\n",
        "        df, CLASSE_COLUMN_NAME, classe)\n",
        "    df_balanced = create_balanced_df(df_classe, df_outrasClasses)\n",
        "    mark_classe(df_balanced)\n",
        "    ementas = df_balanced[EMENTA_COLUMN_NAME]\n",
        "    markers = df_balanced[MARKER_COLUMN_NAME]\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        ementas, markers, stratify=markers)\n",
        "    model = create_keras_model()\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=METRICS)\n",
        "    model.fit(X_train, y_train, epochs=10)\n",
        "    evaluate_model(model, X_test)\n",
        "    nomeArquivoModelo = classe + '_bert_model.h5'\n",
        "    model.save(nomeArquivoModelo)\n",
        "    return model"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.12 ('mdenv')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "bb26a599782b3853c870df2c7a4979ed6ea3ce3b4ae25b1f6e4fc2e40113204d"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
