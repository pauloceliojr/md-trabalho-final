{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Text Classification - OneClass Classificaiton"]},{"cell_type":"markdown","metadata":{},"source":["The one-class algorithms are based on recognition since their aim is to recognize data from a particular class, and reject data from all other classes. This is accomplished by creating a boundary that encompasses all the data belonging to the target class within itself, so when a new sample arrives the algorithm only has to check whether it lies within the boundary or outside and accordingly classify the sample as belonging to the target class or the outlier."]},{"cell_type":"markdown","metadata":{},"source":["Things we are going to discuss:\n","\n","1. Data Preparation \n","2. Cleaning and Tokenization\n","3. Feature Extraction\n","4. Train One-class classificaiton model\n","5. Predict one-class on test data"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Load packages\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.feature_extraction.text import TfidfTransformer\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.feature_extraction.text import HashingVectorizer\n","from sklearn.base import TransformerMixin\n","from sklearn.pipeline import Pipeline\n","from sklearn.svm import OneClassSVM\n","from sklearn.utils import shuffle\n","from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import confusion_matrix \n","from sklearn.metrics import classification_report \n","from nltk.corpus import stopwords\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from nltk.stem.porter import PorterStemmer\n","import string\n","import spacy\n","from spacy.lang.en import English\n","spacy.load('en')\n","parser = English()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# load dataset\n","bbc_df = pd.read_csv('../input/bbc-text.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["bbc_df.head(10)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["bbc_df.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["bbc_df.info()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["bbc_df['category'].unique()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["bbc_df['category'].value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["sns.countplot(bbc_df['category'])"]},{"cell_type":"markdown","metadata":{},"source":["## Data preparation"]},{"cell_type":"markdown","metadata":{},"source":["Let's take \"sport\" category as our traning class for one-class classification\n","\n","so let's replace the category labels\n","\n","Since \"sport\" is our traning class let's replace \"sport\" with \"1\" and replace \"business, politics, tech and entertainment\" with \"-1\"\n","\n","becuase one-class classification model prediction will be 1 or -1\n","\n","here \"1\" is target class and \"-1\" is the outlier"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# change category labels\n","bbc_df['category'] = bbc_df['category'].map({'sport':1,'business':-1,'politics':-1,'tech':-1,'entertainment':-1})"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# create a new dataset with only sport category data\n","sports_df = bbc_df[bbc_df['category'] == 1]"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["sports_df.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# create train and test data\n","train_text = sports_df['text'].tolist()\n","train_labels = sports_df['category'].tolist()\n","\n","test_text = bbc_df['text'].tolist()\n","test_labels = bbc_df['category'].tolist()"]},{"cell_type":"markdown","metadata":{},"source":["## Data Cleaning and Tokenization"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# stop words list\n","STOPLIST = set(stopwords.words('english') + list(ENGLISH_STOP_WORDS)) \n","# special characters\n","SYMBOLS = \" \".join(string.punctuation).split(\" \") + [\"-\", \"...\", \"”\", \"”\",\"''\"]"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# class for cleaning the text\n","class CleanTextTransformer(TransformerMixin):\n","    def transform(self, X, **transform_params):\n","        return [cleanText(text) for text in X]\n","    def fit(self, X, y=None, **fit_params):\n","        return self\n","    def get_params(self, deep=True):\n","            return {}\n","\n","def cleanText(text):\n","    text = text.strip().replace(\"\\n\", \" \").replace(\"\\r\", \" \")\n","    text = text.lower()\n","    return text"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# tokenizing the raw text\n","def tokenizeText(sample):\n","    \n","    tokens = parser(sample)\n","    \n","    # lemmatization\n","    lemmas = []\n","    for tok in tokens:\n","        lemmas.append(tok.lemma_.lower().strip() if tok.lemma_ != \"-PRON-\" else tok.lower_)\n","    tokens = lemmas\n","    \n","    # remove stop words and special characters\n","    tokens = [tok for tok in tokens if tok.lower() not in STOPLIST]\n","    tokens = [tok for tok in tokens if tok not in SYMBOLS]\n","    \n","    # only take words with length greater than or equal to 3\n","    tokens = [tok for tok in tokens if len(tok) >= 3]\n","    \n","    # remove remaining tokens that are not alphabetic\n","    tokens = [tok for tok in tokens if tok.isalpha()]\n","    \n","    # stemming of words\n","    porter = PorterStemmer()\n","    tokens = [porter.stem(word) for word in tokens]\n","    \n","    return list(set(tokens))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# lets see tokenized random text\n","tokenizeText(train_text[9])"]},{"cell_type":"markdown","metadata":{},"source":["## Feature Extraction"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# getting features\n","vectorizer = HashingVectorizer(n_features=20,tokenizer=tokenizeText)\n","\n","features = vectorizer.fit_transform(train_text).toarray()\n","features.shape"]},{"cell_type":"markdown","metadata":{},"source":["## One-class SVM"]},{"cell_type":"markdown","metadata":{},"source":["One-class SVM is an unsupervised algorithm that learns a decision function for novelty detection: classifying new data as similar or different to the training set."]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# OneClassSVM algorithm\n","clf = OneClassSVM(nu=0.1, kernel=\"rbf\", gamma=0.1)\n","pipe_clf = Pipeline([('cleanText', CleanTextTransformer()), ('vectorizer', vectorizer), ('clf', clf)])"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# fit OneClassSVM model \n","pipe_clf.fit(train_text, train_labels)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# validate OneClassSVM model with train set\n","preds_train = pipe_clf.predict(train_text)\n","\n","print(\"accuracy:\", accuracy_score(train_labels, preds_train))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# validate OneClassSVM model with test set\n","preds_test = pipe_clf.predict(test_text)\n","preds_test"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["results = confusion_matrix(test_labels, preds_test) \n","print('Confusion Matrix :')\n","print(results) \n","print('Accuracy Score :',accuracy_score(test_labels, preds_test)) \n","print('Report : ')\n","print(classification_report(test_labels, preds_test)) "]},{"cell_type":"markdown","metadata":{},"source":["Let's check how model is performing "]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# let's take random text from dataset\n","test_text[3]"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# check actual category\n","test_labels[3]"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"trusted":true},"outputs":[],"source":["# let's predict the category of above random text\n","pipe_clf.predict([test_text[3]])"]},{"cell_type":"markdown","metadata":{},"source":["our model predicted random text as sport category which is correct"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3.9.12 ('base')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"},"vscode":{"interpreter":{"hash":"81e257058df10583e9d8d11ec74e8dbfa2c26d0d059139d21bb13510adff3663"}}},"nbformat":4,"nbformat_minor":4}
